[30/4984] loss 0.6828
[60/4984] loss 0.6582
[90/4984] loss 0.6551
[120/4984] loss 0.6357
[150/4984] loss 0.6177
[180/4984] loss 0.6385
[210/4984] loss 0.6360
[240/4984] loss 0.5894
[270/4984] loss 0.6454
[300/4984] loss 0.5773
[330/4984] loss 0.5899
[360/4984] loss 0.6157
[390/4984] loss 0.6713
[420/4984] loss 0.6223
[450/4984] loss 0.6506
[480/4984] loss 0.6383
[510/4984] loss 0.6395
[540/4984] loss 0.6370
[570/4984] loss 0.5898
[600/4984] loss 0.5942
[630/4984] loss 0.6095
[660/4984] loss 0.5925
[690/4984] loss 0.5886
[720/4984] loss 0.6783
[750/4984] loss 0.5870
[780/4984] loss 0.5712
[810/4984] loss 0.6580
[840/4984] loss 0.5995
[870/4984] loss 0.6373
[900/4984] loss 0.5738
[930/4984] loss 0.6130
[960/4984] loss 0.5857
[990/4984] loss 0.6956
[1020/4984] loss 0.6063
[1050/4984] loss 0.6084
[1080/4984] loss 0.5698
[1110/4984] loss 0.5939
[1140/4984] loss 0.5707
[1170/4984] loss 0.5777
[1200/4984] loss 0.5360
[1230/4984] loss 0.6200
[1260/4984] loss 0.6055
[1290/4984] loss 0.5895
[1320/4984] loss 0.5826
[1350/4984] loss 0.5334
[1380/4984] loss 0.6643
[1410/4984] loss 0.5710
[1440/4984] loss 0.5944
[1470/4984] loss 0.5927
[1500/4984] loss 0.6440
[1530/4984] loss 0.6231
[1560/4984] loss 0.5947
[1590/4984] loss 0.5546
[1620/4984] loss 0.6032
[1650/4984] loss 0.5895
[1680/4984] loss 0.5834
[1710/4984] loss 0.5821
[1740/4984] loss 0.6856
[1770/4984] loss 0.6305
[1800/4984] loss 0.5367
[1830/4984] loss 0.5883
[1860/4984] loss 0.6553
[1890/4984] loss 0.5912
[1920/4984] loss 0.5868
[1950/4984] loss 0.6066
[1980/4984] loss 0.6186
[2010/4984] loss 0.5782
[2040/4984] loss 0.5356
[2070/4984] loss 0.5672
[2100/4984] loss 0.5936
[2130/4984] loss 0.6333
[2160/4984] loss 0.6089
[2190/4984] loss 0.5913
[2220/4984] loss 0.5652
[2250/4984] loss 0.6026
[2280/4984] loss 0.5330
[2310/4984] loss 0.6703
[2340/4984] loss 0.5254
[2370/4984] loss 0.6310
[2400/4984] loss 0.6079
[2430/4984] loss 0.5495
[2460/4984] loss 0.6119
[2490/4984] loss 0.6092
[2520/4984] loss 0.5929
[2550/4984] loss 0.5871
[2580/4984] loss 0.5761
[2610/4984] loss 0.5285
[2640/4984] loss 0.6361
[2670/4984] loss 0.5637
[2700/4984] loss 0.6114
[2730/4984] loss 0.5911
[2760/4984] loss 0.5863
[2790/4984] loss 0.6141
[2820/4984] loss 0.5719
[2850/4984] loss 0.5230
[2880/4984] loss 0.5756
[2910/4984] loss 0.6428
[2940/4984] loss 0.6429
[2970/4984] loss 0.6363
[3000/4984] loss 0.6236
[3030/4984] loss 0.5941
[3060/4984] loss 0.6295
[3090/4984] loss 0.5614
[3120/4984] loss 0.5746
[3150/4984] loss 0.5594
[3180/4984] loss 0.5699
[3210/4984] loss 0.5392
[3240/4984] loss 0.6430
[3270/4984] loss 0.5707
[3300/4984] loss 0.6349
[3330/4984] loss 0.5903
[3360/4984] loss 0.6598
[3390/4984] loss 0.5808
[3420/4984] loss 0.5775
[3450/4984] loss 0.5319
[3480/4984] loss 0.6229
[3510/4984] loss 0.5995
[3540/4984] loss 0.5916
[3570/4984] loss 0.5123
[3600/4984] loss 0.5939
[3630/4984] loss 0.6093
[3660/4984] loss 0.6103
[3690/4984] loss 0.4902
[3720/4984] loss 0.6813
[3750/4984] loss 0.5256
[3780/4984] loss 0.5702
[3810/4984] loss 0.5673
[3840/4984] loss 0.6592
[3870/4984] loss 0.5897
[3900/4984] loss 0.5670
[3930/4984] loss 0.5898
[3960/4984] loss 0.6281
[3990/4984] loss 0.5756
[4020/4984] loss 0.5271
[4050/4984] loss 0.5513
[4080/4984] loss 0.6011
[4110/4984] loss 0.5948
[4140/4984] loss 0.6262
[4170/4984] loss 0.5618
[4200/4984] loss 0.5927
[4230/4984] loss 0.5535
[4260/4984] loss 0.5675
[4290/4984] loss 0.5714
[4320/4984] loss 0.6019
[4350/4984] loss 0.5799
[4380/4984] loss 0.5704
[4410/4984] loss 0.5536
[4440/4984] loss 0.5430
[4470/4984] loss 0.5662
[4500/4984] loss 0.5677
[4530/4984] loss 0.6005
[4560/4984] loss 0.5770
[4590/4984] loss 0.6168
[4620/4984] loss 0.6627
[4650/4984] loss 0.5997
[4680/4984] loss 0.5700
[4710/4984] loss 0.6106
[4740/4984] loss 0.5780
[4770/4984] loss 0.4920
[4800/4984] loss 0.6157
[4830/4984] loss 0.5995
[4860/4984] loss 0.5839
[4890/4984] loss 0.5307
[4920/4984] loss 0.5101
[4950/4984] loss 0.5691
[4980/4984] loss 0.5651
[30/1246] evaluation loss 0.6285
[60/1246] evaluation loss 0.6127
[90/1246] evaluation loss 0.5521
[120/1246] evaluation loss 0.5855
[150/1246] evaluation loss 0.5347
[180/1246] evaluation loss 0.5788
[210/1246] evaluation loss 0.5374
[240/1246] evaluation loss 0.6542
[270/1246] evaluation loss 0.5826
[300/1246] evaluation loss 0.5412
[330/1246] evaluation loss 0.5380
[360/1246] evaluation loss 0.5660
[390/1246] evaluation loss 0.5482
[420/1246] evaluation loss 0.6055
[450/1246] evaluation loss 0.5443
[480/1246] evaluation loss 0.5502
[510/1246] evaluation loss 0.5269
[540/1246] evaluation loss 0.5883
[570/1246] evaluation loss 0.5621
[600/1246] evaluation loss 0.5441
[630/1246] evaluation loss 0.5402
[660/1246] evaluation loss 0.5453
[690/1246] evaluation loss 0.5518
[720/1246] evaluation loss 0.5787
[750/1246] evaluation loss 0.5954
[780/1246] evaluation loss 0.5046
[810/1246] evaluation loss 0.5857
[840/1246] evaluation loss 0.5919
[870/1246] evaluation loss 0.5870
[900/1246] evaluation loss 0.5256
[930/1246] evaluation loss 0.5679
[960/1246] evaluation loss 0.5764
[990/1246] evaluation loss 0.6148
[1020/1246] evaluation loss 0.5536
[1050/1246] evaluation loss 0.5633
[1080/1246] evaluation loss 0.5315
[1110/1246] evaluation loss 0.5965
[1140/1246] evaluation loss 0.6018
[1170/1246] evaluation loss 0.5662
[1200/1246] evaluation loss 0.5475
[1230/1246] evaluation loss 0.6128
Epoch 1 training loss 0.5952
Epoch 1 evaluation loss 0.5711
Metrics {'Accuracy': tensor(0.7153), 'Precision': tensor(0.6667), 'Recall': tensor(0.0112), 'F1Score': tensor(0.0221), 'MatthewsCorrCoef': tensor(0.0585)}
[30/4984] loss 0.4823
[60/4984] loss 0.5339
[90/4984] loss 0.5484
[120/4984] loss 0.5915
[150/4984] loss 0.5824
[180/4984] loss 0.5485
[210/4984] loss 0.5064
[240/4984] loss 0.5482
[270/4984] loss 0.4999
[300/4984] loss 0.6036
[330/4984] loss 0.5769
[360/4984] loss 0.5013
[390/4984] loss 0.6037
[420/4984] loss 0.5870
[450/4984] loss 0.5252
[480/4984] loss 0.5385
[510/4984] loss 0.5217
[540/4984] loss 0.5417
[570/4984] loss 0.5809
[600/4984] loss 0.5159
[630/4984] loss 0.4758
[660/4984] loss 0.5587
[690/4984] loss 0.5934
[720/4984] loss 0.5251
[750/4984] loss 0.5890
[780/4984] loss 0.5487
[810/4984] loss 0.5005
[840/4984] loss 0.4912
[870/4984] loss 0.5026
[900/4984] loss 0.5883
[930/4984] loss 0.4909
[960/4984] loss 0.5392
[990/4984] loss 0.5737
[1020/4984] loss 0.4945
[1050/4984] loss 0.5411
[1080/4984] loss 0.5891
[1110/4984] loss 0.6199
[1140/4984] loss 0.5317
[1170/4984] loss 0.5171
[1200/4984] loss 0.5062
[1230/4984] loss 0.4918
[1260/4984] loss 0.5339
[1290/4984] loss 0.5659
[1320/4984] loss 0.4342
[1350/4984] loss 0.4866
[1380/4984] loss 0.4999
[1410/4984] loss 0.6106
[1440/4984] loss 0.5731
[1470/4984] loss 0.5513
[1500/4984] loss 0.5394
[1530/4984] loss 0.5405
[1560/4984] loss 0.5155
[1590/4984] loss 0.5314
[1620/4984] loss 0.5792
[1650/4984] loss 0.5702
[1680/4984] loss 0.5761
[1710/4984] loss 0.5251
[1740/4984] loss 0.5387
[1770/4984] loss 0.5633
[1800/4984] loss 0.5701
[1830/4984] loss 0.5629
[1860/4984] loss 0.5108
[1890/4984] loss 0.5523
[1920/4984] loss 0.5773
[1950/4984] loss 0.5205
[1980/4984] loss 0.6043
[2010/4984] loss 0.5549
[2040/4984] loss 0.5519
[2070/4984] loss 0.5170
[2100/4984] loss 0.4806
[2130/4984] loss 0.4521
[2160/4984] loss 0.4989
[2190/4984] loss 0.5822
[2220/4984] loss 0.5253
[2250/4984] loss 0.5661
[2280/4984] loss 0.5643
[2310/4984] loss 0.5131
[2340/4984] loss 0.5240
[2370/4984] loss 0.4788
[2400/4984] loss 0.5832
[2430/4984] loss 0.5463
[2460/4984] loss 0.4543
[2490/4984] loss 0.5142
[2520/4984] loss 0.6509
[2550/4984] loss 0.5528
[2580/4984] loss 0.5219
[2610/4984] loss 0.5486
[2640/4984] loss 0.5309
[2670/4984] loss 0.5185
[2700/4984] loss 0.6177
[2730/4984] loss 0.5197
[2760/4984] loss 0.4562
[2790/4984] loss 0.5502
[2820/4984] loss 0.5026
[2850/4984] loss 0.5203
[2880/4984] loss 0.5699
[2910/4984] loss 0.5508
[2940/4984] loss 0.6025
[2970/4984] loss 0.5042
[3000/4984] loss 0.5365
[3030/4984] loss 0.5651
[3060/4984] loss 0.5684
[3090/4984] loss 0.6122
[3120/4984] loss 0.5711
[3150/4984] loss 0.5398
[3180/4984] loss 0.5985
[3210/4984] loss 0.6041
[3240/4984] loss 0.5597
[3270/4984] loss 0.5884
[3300/4984] loss 0.5966
[3330/4984] loss 0.5515
[3360/4984] loss 0.5190
[3390/4984] loss 0.5752
[3420/4984] loss 0.4639
[3450/4984] loss 0.5480
[3480/4984] loss 0.5344
[3510/4984] loss 0.5380
[3540/4984] loss 0.6291
[3570/4984] loss 0.5577
[3600/4984] loss 0.5196
[3630/4984] loss 0.4808
[3660/4984] loss 0.5759
[3690/4984] loss 0.5461
[3720/4984] loss 0.4722
[3750/4984] loss 0.4530
[3780/4984] loss 0.5847
[3810/4984] loss 0.5537
[3840/4984] loss 0.5228
[3870/4984] loss 0.4951
[3900/4984] loss 0.5045
[3930/4984] loss 0.4924
[3960/4984] loss 0.5930
[3990/4984] loss 0.5753
[4020/4984] loss 0.5474
[4050/4984] loss 0.5221
[4080/4984] loss 0.5101
[4110/4984] loss 0.4852
[4140/4984] loss 0.5495
[4170/4984] loss 0.5516
[4200/4984] loss 0.4990
[4230/4984] loss 0.4995
[4260/4984] loss 0.5629
[4290/4984] loss 0.4839
[4320/4984] loss 0.4930
[4350/4984] loss 0.6162
[4380/4984] loss 0.4690
[4410/4984] loss 0.4908
[4440/4984] loss 0.5895
[4470/4984] loss 0.5345
[4500/4984] loss 0.4774
[4530/4984] loss 0.5599
[4560/4984] loss 0.4778
[4590/4984] loss 0.5689
[4620/4984] loss 0.5309
[4650/4984] loss 0.4687
[4680/4984] loss 0.5119
[4710/4984] loss 0.5380
[4740/4984] loss 0.4557
[4770/4984] loss 0.4990
[4800/4984] loss 0.5678
[4830/4984] loss 0.6151
[4860/4984] loss 0.4641
[4890/4984] loss 0.4859
[4920/4984] loss 0.4838
[4950/4984] loss 0.5870
[4980/4984] loss 0.5382
[30/1246] evaluation loss 0.5653
[60/1246] evaluation loss 0.5883
[90/1246] evaluation loss 0.5045
[120/1246] evaluation loss 0.5913
[150/1246] evaluation loss 0.5384
[180/1246] evaluation loss 0.5413
[210/1246] evaluation loss 0.5757
[240/1246] evaluation loss 0.5296
[270/1246] evaluation loss 0.5133
[300/1246] evaluation loss 0.5162
[330/1246] evaluation loss 0.4945
[360/1246] evaluation loss 0.4914
[390/1246] evaluation loss 0.4839
[420/1246] evaluation loss 0.5941
[450/1246] evaluation loss 0.5840
[480/1246] evaluation loss 0.4797
[510/1246] evaluation loss 0.4511
[540/1246] evaluation loss 0.5070
[570/1246] evaluation loss 0.6647
[600/1246] evaluation loss 0.5962
[630/1246] evaluation loss 0.5191
[660/1246] evaluation loss 0.5532
[690/1246] evaluation loss 0.5464
[720/1246] evaluation loss 0.5262
[750/1246] evaluation loss 0.5208
[780/1246] evaluation loss 0.5234
[810/1246] evaluation loss 0.5404
[840/1246] evaluation loss 0.4651
[870/1246] evaluation loss 0.5289
[900/1246] evaluation loss 0.5143
[930/1246] evaluation loss 0.5004
[960/1246] evaluation loss 0.5070
[990/1246] evaluation loss 0.5656
[1020/1246] evaluation loss 0.5939
[1050/1246] evaluation loss 0.5436
[1080/1246] evaluation loss 0.4693
[1110/1246] evaluation loss 0.5092
[1140/1246] evaluation loss 0.6002
[1170/1246] evaluation loss 0.4831
[1200/1246] evaluation loss 0.5956
[1230/1246] evaluation loss 0.5758
Epoch 2 training loss 0.5380
Epoch 2 evaluation loss 0.5369
Metrics {'Accuracy': tensor(0.7331), 'Precision': tensor(0.5424), 'Recall': tensor(0.4352), 'F1Score': tensor(0.4829), 'MatthewsCorrCoef': tensor(0.3093)}
[30/4984] loss 0.4560
[60/4984] loss 0.4964
[90/4984] loss 0.4759
[120/4984] loss 0.5241
[150/4984] loss 0.5340
[180/4984] loss 0.4282
[210/4984] loss 0.5132
[240/4984] loss 0.4298
[270/4984] loss 0.5652
[300/4984] loss 0.5363
[330/4984] loss 0.5017
[360/4984] loss 0.5263
[390/4984] loss 0.4802
[420/4984] loss 0.4703
[450/4984] loss 0.4455
[480/4984] loss 0.4841
[510/4984] loss 0.4649
[540/4984] loss 0.5424
[570/4984] loss 0.4899
[600/4984] loss 0.4919
[630/4984] loss 0.5217
[660/4984] loss 0.4380
[690/4984] loss 0.4781
[720/4984] loss 0.4387
[750/4984] loss 0.4677
[780/4984] loss 0.4988
[810/4984] loss 0.4930
[840/4984] loss 0.4760
[870/4984] loss 0.4620
[900/4984] loss 0.4244
[930/4984] loss 0.4865
[960/4984] loss 0.4772
[990/4984] loss 0.4637
[1020/4984] loss 0.4849
[1050/4984] loss 0.4683
[1080/4984] loss 0.5954
[1110/4984] loss 0.4857
[1140/4984] loss 0.4323
[1170/4984] loss 0.5128
[1200/4984] loss 0.5223
[1230/4984] loss 0.4302
[1260/4984] loss 0.4356
[1290/4984] loss 0.5174
[1320/4984] loss 0.4989
[1350/4984] loss 0.5351
[1380/4984] loss 0.4097
[1410/4984] loss 0.4722
[1440/4984] loss 0.4920
[1470/4984] loss 0.4052
[1500/4984] loss 0.4675
[1530/4984] loss 0.4958
[1560/4984] loss 0.5053
[1590/4984] loss 0.4656
[1620/4984] loss 0.4410
[1650/4984] loss 0.4696
[1680/4984] loss 0.5412
[1710/4984] loss 0.4353
[1740/4984] loss 0.4474
[1770/4984] loss 0.4913
[1800/4984] loss 0.4347
[1830/4984] loss 0.4768
[1860/4984] loss 0.5170
[1890/4984] loss 0.3946
[1920/4984] loss 0.4261
[1950/4984] loss 0.4725
[1980/4984] loss 0.4412
[2010/4984] loss 0.4813
[2040/4984] loss 0.5312
[2070/4984] loss 0.4630
[2100/4984] loss 0.5160
[2130/4984] loss 0.4880
[2160/4984] loss 0.4774
[2190/4984] loss 0.4507
[2220/4984] loss 0.5906
[2250/4984] loss 0.4488
[2280/4984] loss 0.4506
[2310/4984] loss 0.4854
[2340/4984] loss 0.4425
[2370/4984] loss 0.4984
[2400/4984] loss 0.4447
[2430/4984] loss 0.4902
[2460/4984] loss 0.4678
[2490/4984] loss 0.4184
[2520/4984] loss 0.4315
[2550/4984] loss 0.4898
[2580/4984] loss 0.4433
[2610/4984] loss 0.5237
[2640/4984] loss 0.5733
[2670/4984] loss 0.4570
[2700/4984] loss 0.4829
[2730/4984] loss 0.4479
[2760/4984] loss 0.5393
[2790/4984] loss 0.6211
[2820/4984] loss 0.4590
[2850/4984] loss 0.5737
[2880/4984] loss 0.5062
[2910/4984] loss 0.5294
[2940/4984] loss 0.5089
[2970/4984] loss 0.4434
[3000/4984] loss 0.4253
[3030/4984] loss 0.5634
[3060/4984] loss 0.4844
[3090/4984] loss 0.4910
[3120/4984] loss 0.4982
[3150/4984] loss 0.5135
[3180/4984] loss 0.4199
[3210/4984] loss 0.3686
[3240/4984] loss 0.4628
[3270/4984] loss 0.5332
[3300/4984] loss 0.4631
[3330/4984] loss 0.4521
[3360/4984] loss 0.5740
[3390/4984] loss 0.5588
[3420/4984] loss 0.4747
[3450/4984] loss 0.4810
[3480/4984] loss 0.4213
[3510/4984] loss 0.4857
[3540/4984] loss 0.4610
[3570/4984] loss 0.4844
[3600/4984] loss 0.4849
[3630/4984] loss 0.5290
[3660/4984] loss 0.5207
[3690/4984] loss 0.4674
[3720/4984] loss 0.4960
[3750/4984] loss 0.4333
[3780/4984] loss 0.4101
[3810/4984] loss 0.4475
[3840/4984] loss 0.4503
[3870/4984] loss 0.4920
[3900/4984] loss 0.4865
[3930/4984] loss 0.4775
[3960/4984] loss 0.5138
[3990/4984] loss 0.4417
[4020/4984] loss 0.4100
[4050/4984] loss 0.4196
[4080/4984] loss 0.5872
[4110/4984] loss 0.4881
[4140/4984] loss 0.4722
[4170/4984] loss 0.5189
[4200/4984] loss 0.3891
[4230/4984] loss 0.4558
[4260/4984] loss 0.5061
[4290/4984] loss 0.4060
[4320/4984] loss 0.4051
[4350/4984] loss 0.4282
[4380/4984] loss 0.4424
[4410/4984] loss 0.4563
[4440/4984] loss 0.4179
[4470/4984] loss 0.4487
[4500/4984] loss 0.4146
[4530/4984] loss 0.4845
[4560/4984] loss 0.5751
[4590/4984] loss 0.5281
[4620/4984] loss 0.4821
[4650/4984] loss 0.4537
[4680/4984] loss 0.3976
[4710/4984] loss 0.4447
[4740/4984] loss 0.4499
[4770/4984] loss 0.4288
[4800/4984] loss 0.4531
[4830/4984] loss 0.4974
[4860/4984] loss 0.5021
[4890/4984] loss 0.4578
[4920/4984] loss 0.4831
[4950/4984] loss 0.4371
[4980/4984] loss 0.3963
[30/1246] evaluation loss 0.4754
[60/1246] evaluation loss 0.4929
[90/1246] evaluation loss 0.5852
[120/1246] evaluation loss 0.6202
[150/1246] evaluation loss 0.4273
[180/1246] evaluation loss 0.5547
[210/1246] evaluation loss 0.5553
[240/1246] evaluation loss 0.5497
[270/1246] evaluation loss 0.5052
[300/1246] evaluation loss 0.5093
[330/1246] evaluation loss 0.4648
[360/1246] evaluation loss 0.5252
[390/1246] evaluation loss 0.4611
[420/1246] evaluation loss 0.5329
[450/1246] evaluation loss 0.5245
[480/1246] evaluation loss 0.4592
[510/1246] evaluation loss 0.5684
[540/1246] evaluation loss 0.5065
[570/1246] evaluation loss 0.5866
[600/1246] evaluation loss 0.5190
[630/1246] evaluation loss 0.5503
[660/1246] evaluation loss 0.5246
[690/1246] evaluation loss 0.5414
[720/1246] evaluation loss 0.6011
[750/1246] evaluation loss 0.6449
[780/1246] evaluation loss 0.5262
[810/1246] evaluation loss 0.6137
[840/1246] evaluation loss 0.5245
[870/1246] evaluation loss 0.4549
[900/1246] evaluation loss 0.5436
[930/1246] evaluation loss 0.6436
[960/1246] evaluation loss 0.4604
[990/1246] evaluation loss 0.5149
[1020/1246] evaluation loss 0.5335
[1050/1246] evaluation loss 0.4182
[1080/1246] evaluation loss 0.5026
[1110/1246] evaluation loss 0.5015
[1140/1246] evaluation loss 0.4505
[1170/1246] evaluation loss 0.5566
[1200/1246] evaluation loss 0.5300
[1230/1246] evaluation loss 0.5789
Epoch 3 training loss 0.4773
Epoch 3 evaluation loss 0.5273
Metrics {'Accuracy': tensor(0.7522), 'Precision': tensor(0.5768), 'Recall': tensor(0.5053), 'F1Score': tensor(0.5387), 'MatthewsCorrCoef': tensor(0.3718)}
[30/4984] loss 0.5120
[60/4984] loss 0.4348
[90/4984] loss 0.4844
[120/4984] loss 0.4140
[150/4984] loss 0.4834
[180/4984] loss 0.4701
[210/4984] loss 0.3864
[240/4984] loss 0.4648
[270/4984] loss 0.3619
[300/4984] loss 0.4419
[330/4984] loss 0.5442
[360/4984] loss 0.4173
[390/4984] loss 0.3957
[420/4984] loss 0.3672
[450/4984] loss 0.4270
[480/4984] loss 0.4492
[510/4984] loss 0.3866
[540/4984] loss 0.3816
[570/4984] loss 0.4326
[600/4984] loss 0.3667
[630/4984] loss 0.3781
[660/4984] loss 0.3940
[690/4984] loss 0.3565
[720/4984] loss 0.3600
[750/4984] loss 0.4462
[780/4984] loss 0.4639
[810/4984] loss 0.4540
[840/4984] loss 0.5236
[870/4984] loss 0.4413
[900/4984] loss 0.3429
[930/4984] loss 0.4142
[960/4984] loss 0.4479
[990/4984] loss 0.3516
[1020/4984] loss 0.4065
[1050/4984] loss 0.4119
[1080/4984] loss 0.3971
[1110/4984] loss 0.3600
[1140/4984] loss 0.4978
[1170/4984] loss 0.3943
[1200/4984] loss 0.4373
[1230/4984] loss 0.3632
[1260/4984] loss 0.4706
[1290/4984] loss 0.4041
[1320/4984] loss 0.4226
[1350/4984] loss 0.3503
[1380/4984] loss 0.4531
[1410/4984] loss 0.5410
[1440/4984] loss 0.3989
[1470/4984] loss 0.4122
[1500/4984] loss 0.4019
[1530/4984] loss 0.3543
[1560/4984] loss 0.3646
[1590/4984] loss 0.3095
[1620/4984] loss 0.4207
[1650/4984] loss 0.5033
[1680/4984] loss 0.5135
[1710/4984] loss 0.4273
[1740/4984] loss 0.4798
[1770/4984] loss 0.4379
[1800/4984] loss 0.4594
[1830/4984] loss 0.4301
[1860/4984] loss 0.4342
[1890/4984] loss 0.3732
[1920/4984] loss 0.4136
[1950/4984] loss 0.4046
[1980/4984] loss 0.3885
[2010/4984] loss 0.4638
[2040/4984] loss 0.4277
[2070/4984] loss 0.3535
[2100/4984] loss 0.4122
[2130/4984] loss 0.4065
[2160/4984] loss 0.4348
[2190/4984] loss 0.3634
[2220/4984] loss 0.4214
[2250/4984] loss 0.3036
[2280/4984] loss 0.4897
[2310/4984] loss 0.4210
[2340/4984] loss 0.4799
[2370/4984] loss 0.4438
[2400/4984] loss 0.5194
[2430/4984] loss 0.4664
[2460/4984] loss 0.4661
[2490/4984] loss 0.3982
[2520/4984] loss 0.3687
[2550/4984] loss 0.4162
[2580/4984] loss 0.5085
[2610/4984] loss 0.3956
[2640/4984] loss 0.4018
[2670/4984] loss 0.4056
[2700/4984] loss 0.3944
[2730/4984] loss 0.4109
[2760/4984] loss 0.4170
[2790/4984] loss 0.4785
[2820/4984] loss 0.5059
[2850/4984] loss 0.4829
[2880/4984] loss 0.3972
[2910/4984] loss 0.3999
[2940/4984] loss 0.4449
[2970/4984] loss 0.4194
[3000/4984] loss 0.4705
[3030/4984] loss 0.4853
[3060/4984] loss 0.3784
[3090/4984] loss 0.4128
[3120/4984] loss 0.4072
[3150/4984] loss 0.4074
[3180/4984] loss 0.4374
[3210/4984] loss 0.5068
[3240/4984] loss 0.4018
[3270/4984] loss 0.4874
[3300/4984] loss 0.3749
[3330/4984] loss 0.3546
[3360/4984] loss 0.3957
[3390/4984] loss 0.3568
[3420/4984] loss 0.4144
[3450/4984] loss 0.4008
[3480/4984] loss 0.3947
[3510/4984] loss 0.3712
[3540/4984] loss 0.4185
[3570/4984] loss 0.3881
[3600/4984] loss 0.4725
[3630/4984] loss 0.4055
[3660/4984] loss 0.4162
[3690/4984] loss 0.3679
[3720/4984] loss 0.5266
[3750/4984] loss 0.4256
[3780/4984] loss 0.3883
[3810/4984] loss 0.3879
[3840/4984] loss 0.3618
[3870/4984] loss 0.4199
[3900/4984] loss 0.4054
[3930/4984] loss 0.5369
[3960/4984] loss 0.4983
[3990/4984] loss 0.3931
[4020/4984] loss 0.4042
[4050/4984] loss 0.3885
[4080/4984] loss 0.4317
[4110/4984] loss 0.4528
[4140/4984] loss 0.3836
[4170/4984] loss 0.4241
[4200/4984] loss 0.3755
[4230/4984] loss 0.4422
[4260/4984] loss 0.4262
[4290/4984] loss 0.3947
[4320/4984] loss 0.3899
[4350/4984] loss 0.4368
[4380/4984] loss 0.4082
[4410/4984] loss 0.3398
[4440/4984] loss 0.4175
[4470/4984] loss 0.4169
[4500/4984] loss 0.4068
[4530/4984] loss 0.3887
[4560/4984] loss 0.4235
[4590/4984] loss 0.3612
[4620/4984] loss 0.4473
[4650/4984] loss 0.3899
[4680/4984] loss 0.4432
[4710/4984] loss 0.4160
[4740/4984] loss 0.3683
[4770/4984] loss 0.3416
[4800/4984] loss 0.3906
[4830/4984] loss 0.3351
[4860/4984] loss 0.4817
[4890/4984] loss 0.4280
[4920/4984] loss 0.3210
[4950/4984] loss 0.4927
[4980/4984] loss 0.5386
[30/1246] evaluation loss 0.5052
[60/1246] evaluation loss 0.6203
[90/1246] evaluation loss 0.5719
[120/1246] evaluation loss 0.4896
[150/1246] evaluation loss 0.6218
[180/1246] evaluation loss 0.4934
[210/1246] evaluation loss 0.5352
[240/1246] evaluation loss 0.5063
[270/1246] evaluation loss 0.5421
[300/1246] evaluation loss 0.4792
[330/1246] evaluation loss 0.4714
[360/1246] evaluation loss 0.4576
[390/1246] evaluation loss 0.5893
[420/1246] evaluation loss 0.4022
[450/1246] evaluation loss 0.4761
[480/1246] evaluation loss 0.5068
[510/1246] evaluation loss 0.5834
[540/1246] evaluation loss 0.5213
[570/1246] evaluation loss 0.4669
[600/1246] evaluation loss 0.4625
[630/1246] evaluation loss 0.4851
[660/1246] evaluation loss 0.6590
[690/1246] evaluation loss 0.4805
[720/1246] evaluation loss 0.4809
[750/1246] evaluation loss 0.5144
[780/1246] evaluation loss 0.5424
[810/1246] evaluation loss 0.5707
[840/1246] evaluation loss 0.5994
[870/1246] evaluation loss 0.4212
[900/1246] evaluation loss 0.4383
[930/1246] evaluation loss 0.4829
[960/1246] evaluation loss 0.5377
[990/1246] evaluation loss 0.6054
[1020/1246] evaluation loss 0.5814
[1050/1246] evaluation loss 0.4801
[1080/1246] evaluation loss 0.4751
[1110/1246] evaluation loss 0.6364
[1140/1246] evaluation loss 0.4176
[1170/1246] evaluation loss 0.5084
[1200/1246] evaluation loss 0.5446
[1230/1246] evaluation loss 0.5122
Epoch 4 training loss 0.4199
Epoch 4 evaluation loss 0.5187
Metrics {'Accuracy': tensor(0.7552), 'Precision': tensor(0.5829), 'Recall': tensor(0.5102), 'F1Score': tensor(0.5441), 'MatthewsCorrCoef': tensor(0.3794)}
[30/4984] loss 0.3274
[60/4984] loss 0.3846
[90/4984] loss 0.3734
[120/4984] loss 0.2902
[150/4984] loss 0.3009
[180/4984] loss 0.3464
[210/4984] loss 0.3418
[240/4984] loss 0.3213
[270/4984] loss 0.2709
[300/4984] loss 0.3649
[330/4984] loss 0.3362
[360/4984] loss 0.3574
[390/4984] loss 0.3591
[420/4984] loss 0.2935
[450/4984] loss 0.3845
[480/4984] loss 0.2575
[510/4984] loss 0.3241
[540/4984] loss 0.4073
[570/4984] loss 0.3284
[600/4984] loss 0.3632
[630/4984] loss 0.3547
[660/4984] loss 0.3310
[690/4984] loss 0.3639
[720/4984] loss 0.3688
[750/4984] loss 0.4086
[780/4984] loss 0.3698
[810/4984] loss 0.2856
[840/4984] loss 0.4213
[870/4984] loss 0.3296
[900/4984] loss 0.3410
[930/4984] loss 0.3338
[960/4984] loss 0.3235
[990/4984] loss 0.2674
[1020/4984] loss 0.3577
[1050/4984] loss 0.3759
[1080/4984] loss 0.3368
[1110/4984] loss 0.3653
[1140/4984] loss 0.4105
[1170/4984] loss 0.4903
[1200/4984] loss 0.3525
[1230/4984] loss 0.3295
[1260/4984] loss 0.3102
[1290/4984] loss 0.4060
[1320/4984] loss 0.4117
[1350/4984] loss 0.3704
[1380/4984] loss 0.3318
[1410/4984] loss 0.4075
[1440/4984] loss 0.3243
[1470/4984] loss 0.3292
[1500/4984] loss 0.4143
[1530/4984] loss 0.3541
[1560/4984] loss 0.3709
[1590/4984] loss 0.3114
[1620/4984] loss 0.3232
[1650/4984] loss 0.4059
[1680/4984] loss 0.3129
[1710/4984] loss 0.3538
[1740/4984] loss 0.3343
[1770/4984] loss 0.2950
[1800/4984] loss 0.3587
[1830/4984] loss 0.2976
[1860/4984] loss 0.3530
[1890/4984] loss 0.2902
[1920/4984] loss 0.3695
[1950/4984] loss 0.3919
[1980/4984] loss 0.3289
[2010/4984] loss 0.3630
[2040/4984] loss 0.3637
[2070/4984] loss 0.3503
[2100/4984] loss 0.3549
[2130/4984] loss 0.3269
[2160/4984] loss 0.2614
[2190/4984] loss 0.3308
[2220/4984] loss 0.3850
[2250/4984] loss 0.3762
[2280/4984] loss 0.3107
[2310/4984] loss 0.3680
[2340/4984] loss 0.4281
[2370/4984] loss 0.3012
[2400/4984] loss 0.3536
[2430/4984] loss 0.3685
[2460/4984] loss 0.3941
[2490/4984] loss 0.3936
[2520/4984] loss 0.3447
[2550/4984] loss 0.3675
[2580/4984] loss 0.5688
[2610/4984] loss 0.6430
[2640/4984] loss 0.4804
[2670/4984] loss 0.4280
[2700/4984] loss 0.5052
[2730/4984] loss 0.4028
[2760/4984] loss 0.4295
[2790/4984] loss 0.3611
[2820/4984] loss 0.4903
[2850/4984] loss 0.4989
[2880/4984] loss 0.4842
[2910/4984] loss 0.4320
[2940/4984] loss 0.4094
[2970/4984] loss 0.4310
[3000/4984] loss 0.4240
[3030/4984] loss 0.4532
[3060/4984] loss 0.4146
[3090/4984] loss 0.3778
[3120/4984] loss 0.3542
[3150/4984] loss 0.4447
[3180/4984] loss 0.4422
[3210/4984] loss 0.4400
[3240/4984] loss 0.4164
[3270/4984] loss 0.4326
[3300/4984] loss 0.4640
[3330/4984] loss 0.4266
[3360/4984] loss 0.3651
[3390/4984] loss 0.3190
[3420/4984] loss 0.4262
[3450/4984] loss 0.4635
[3480/4984] loss 0.3598
[3510/4984] loss 0.4324
[3540/4984] loss 0.3943
[3570/4984] loss 0.4498
[3600/4984] loss 0.4508
[3630/4984] loss 0.5132
[3660/4984] loss 0.3643
[3690/4984] loss 0.3678
[3720/4984] loss 0.3573
[3750/4984] loss 0.4350
[3780/4984] loss 0.3255
[3810/4984] loss 0.3578
[3840/4984] loss 0.3737
[3870/4984] loss 0.3410
[3900/4984] loss 0.3501
[3930/4984] loss 0.4481
[3960/4984] loss 0.3304
[3990/4984] loss 0.4889
[4020/4984] loss 0.3774
[4050/4984] loss 0.4741
[4080/4984] loss 0.3125
[4110/4984] loss 0.2393
[4140/4984] loss 0.3833
[4170/4984] loss 0.3950
[4200/4984] loss 0.3849
[4230/4984] loss 0.2965
[4260/4984] loss 0.4398
[4290/4984] loss 0.3761
[4320/4984] loss 0.3347
[4350/4984] loss 0.4368
[4380/4984] loss 0.3784
[4410/4984] loss 0.4281
[4440/4984] loss 0.4904
[4470/4984] loss 0.3481
[4500/4984] loss 0.3279
[4530/4984] loss 0.4214
[4560/4984] loss 0.3864
[4590/4984] loss 0.3730
[4620/4984] loss 0.3489
[4650/4984] loss 0.4616
[4680/4984] loss 0.3090
[4710/4984] loss 0.3680
[4740/4984] loss 0.3739
[4770/4984] loss 0.4529
[4800/4984] loss 0.4360
[4830/4984] loss 0.3241
[4860/4984] loss 0.3275
[4890/4984] loss 0.3086
[4920/4984] loss 0.3853
[4950/4984] loss 0.3319
[4980/4984] loss 0.3743
[30/1246] evaluation loss 0.5064
[60/1246] evaluation loss 0.4919
[90/1246] evaluation loss 0.4786
[120/1246] evaluation loss 0.6092
[150/1246] evaluation loss 0.6167
[180/1246] evaluation loss 0.5315
[210/1246] evaluation loss 0.5503
[240/1246] evaluation loss 0.5204
[270/1246] evaluation loss 0.4728
[300/1246] evaluation loss 0.5333
[330/1246] evaluation loss 0.4863
[360/1246] evaluation loss 0.5565
[390/1246] evaluation loss 0.4395
[420/1246] evaluation loss 0.4631
[450/1246] evaluation loss 0.7180
[480/1246] evaluation loss 0.5539
[510/1246] evaluation loss 0.7526
[540/1246] evaluation loss 0.4874
[570/1246] evaluation loss 0.5126
[600/1246] evaluation loss 0.4647
[630/1246] evaluation loss 0.5517
[660/1246] evaluation loss 0.4189
[690/1246] evaluation loss 0.5703
[720/1246] evaluation loss 0.5287
[750/1246] evaluation loss 0.6041
[780/1246] evaluation loss 0.4799
[810/1246] evaluation loss 0.5847
[840/1246] evaluation loss 0.5306
[870/1246] evaluation loss 0.5507
[900/1246] evaluation loss 0.4794
[930/1246] evaluation loss 0.4992
[960/1246] evaluation loss 0.5370
[990/1246] evaluation loss 0.5676
[1020/1246] evaluation loss 0.5391
[1050/1246] evaluation loss 0.4886
[1080/1246] evaluation loss 0.6204
[1110/1246] evaluation loss 0.6114
[1140/1246] evaluation loss 0.5428
[1170/1246] evaluation loss 0.5704
[1200/1246] evaluation loss 0.5664
[1230/1246] evaluation loss 0.5011
Epoch 5 training loss 0.3767
Epoch 5 evaluation loss 0.5394
Metrics {'Accuracy': tensor(0.7518), 'Precision': tensor(0.5783), 'Recall': tensor(0.4919), 'F1Score': tensor(0.5316), 'MatthewsCorrCoef': tensor(0.3665)}
[30/4984] loss 0.3473
[60/4984] loss 0.2272
[90/4984] loss 0.3947
[120/4984] loss 0.3105
[150/4984] loss 0.3236
[180/4984] loss 0.2608
[210/4984] loss 0.2455
[240/4984] loss 0.3795
[270/4984] loss 0.3291
[300/4984] loss 0.4061
[330/4984] loss 0.2699
[360/4984] loss 0.2349
[390/4984] loss 0.2890
[420/4984] loss 0.2863
[450/4984] loss 0.2919
[480/4984] loss 0.3051
[510/4984] loss 0.2994
[540/4984] loss 0.3208
[570/4984] loss 0.3257
[600/4984] loss 0.2645
[630/4984] loss 0.3548
[660/4984] loss 0.2433
[690/4984] loss 0.3376
[720/4984] loss 0.2958
[750/4984] loss 0.2069
[780/4984] loss 0.3901
[810/4984] loss 0.2614
[840/4984] loss 0.2987
[870/4984] loss 0.3124
[900/4984] loss 0.3272
[930/4984] loss 0.2752
[960/4984] loss 0.2882
[990/4984] loss 0.3048
[1020/4984] loss 0.3349
[1050/4984] loss 0.4520
[1080/4984] loss 0.2319
[1110/4984] loss 0.3948
[1140/4984] loss 0.2899
[1170/4984] loss 0.3398
[1200/4984] loss 0.2691
[1230/4984] loss 0.2352
[1260/4984] loss 0.2615
[1290/4984] loss 0.2508
[1320/4984] loss 0.2885
[1350/4984] loss 0.3131
[1380/4984] loss 0.2779
[1410/4984] loss 0.2681
[1440/4984] loss 0.2603
[1470/4984] loss 0.2382
[1500/4984] loss 0.3116
[1530/4984] loss 0.2696
[1560/4984] loss 0.2609
[1590/4984] loss 0.3793
[1620/4984] loss 0.3125
[1650/4984] loss 0.2840
[1680/4984] loss 0.2554
[1710/4984] loss 0.2817
[1740/4984] loss 0.3715
[1770/4984] loss 0.2564
[1800/4984] loss 0.2951
[1830/4984] loss 0.3917
[1860/4984] loss 0.3339
[1890/4984] loss 0.2380
[1920/4984] loss 0.2719
[1950/4984] loss 0.2998
[1980/4984] loss 0.2466
[2010/4984] loss 0.2570
[2040/4984] loss 0.2265
[2070/4984] loss 0.3368
[2100/4984] loss 0.2500
[2130/4984] loss 0.1871
[2160/4984] loss 0.3200
[2190/4984] loss 0.3236
[2220/4984] loss 0.3014
[2250/4984] loss 0.3223
[2280/4984] loss 0.3094
[2310/4984] loss 0.3031
[2340/4984] loss 0.3303
[2370/4984] loss 0.2960
[2400/4984] loss 0.3405
[2430/4984] loss 0.3306
[2460/4984] loss 0.3174
[2490/4984] loss 0.2979
[2520/4984] loss 0.2549
[2550/4984] loss 0.3019
[2580/4984] loss 0.2306
[2610/4984] loss 0.2660
[2640/4984] loss 0.3782
[2670/4984] loss 0.2954
[2700/4984] loss 0.3467
[2730/4984] loss 0.2092
[2760/4984] loss 0.2679
[2790/4984] loss 0.2185
[2820/4984] loss 0.2746
[2850/4984] loss 0.3139
[2880/4984] loss 0.3368
[2910/4984] loss 0.2366
[2940/4984] loss 0.3355
[2970/4984] loss 0.3617
[3000/4984] loss 0.2380
[3030/4984] loss 0.3020
[3060/4984] loss 0.2904
[3090/4984] loss 0.2916
[3120/4984] loss 0.3596
[3150/4984] loss 0.3122
[3180/4984] loss 0.2663
[3210/4984] loss 0.2902
[3240/4984] loss 0.3284
[3270/4984] loss 0.3210
[3300/4984] loss 0.3090
[3330/4984] loss 0.3195
[3360/4984] loss 0.3238
[3390/4984] loss 0.2893
[3420/4984] loss 0.3551
[3450/4984] loss 0.3844
[3480/4984] loss 0.2459
[3510/4984] loss 0.3107
[3540/4984] loss 0.2832
[3570/4984] loss 0.3813
[3600/4984] loss 0.2902
[3630/4984] loss 0.3355
[3660/4984] loss 0.2988
[3690/4984] loss 0.3680
[3720/4984] loss 0.2255
[3750/4984] loss 0.3305
[3780/4984] loss 0.3139
[3810/4984] loss 0.2830
[3840/4984] loss 0.2445
[3870/4984] loss 0.2276
[3900/4984] loss 0.2827
[3930/4984] loss 0.3415
[3960/4984] loss 0.2596
[3990/4984] loss 0.2957
[4020/4984] loss 0.4475
[4050/4984] loss 0.2133
[4080/4984] loss 0.3290
[4110/4984] loss 0.2747
[4140/4984] loss 0.3696
[4170/4984] loss 0.3327
[4200/4984] loss 0.3369
[4230/4984] loss 0.3992
[4260/4984] loss 0.3083
[4290/4984] loss 0.2406
[4320/4984] loss 0.3093
[4350/4984] loss 0.2635
[4380/4984] loss 0.3113
[4410/4984] loss 0.3202
[4440/4984] loss 0.2483
[4470/4984] loss 0.3072
[4500/4984] loss 0.4583
[4530/4984] loss 0.2504
[4560/4984] loss 0.2777
[4590/4984] loss 0.3345
[4620/4984] loss 0.3082
[4650/4984] loss 0.2667
[4680/4984] loss 0.2568
[4710/4984] loss 0.3222
[4740/4984] loss 0.2640
[4770/4984] loss 0.2871
[4800/4984] loss 0.2274
[4830/4984] loss 0.1643
[4860/4984] loss 0.2306
[4890/4984] loss 0.4019
[4920/4984] loss 0.3260
[4950/4984] loss 0.2962
[4980/4984] loss 0.3144
[30/1246] evaluation loss 0.6078
[60/1246] evaluation loss 0.5317
[90/1246] evaluation loss 0.7400
[120/1246] evaluation loss 0.5586
[150/1246] evaluation loss 0.6591
[180/1246] evaluation loss 0.3861
[210/1246] evaluation loss 0.6158
[240/1246] evaluation loss 0.5386
[270/1246] evaluation loss 0.5844
[300/1246] evaluation loss 0.5652
[330/1246] evaluation loss 0.6331
[360/1246] evaluation loss 0.7357
[390/1246] evaluation loss 0.6136
[420/1246] evaluation loss 0.6072
[450/1246] evaluation loss 0.5423
[480/1246] evaluation loss 0.6160
[510/1246] evaluation loss 0.6159
[540/1246] evaluation loss 0.5080
[570/1246] evaluation loss 0.4707
[600/1246] evaluation loss 0.5407
[630/1246] evaluation loss 0.7342
[660/1246] evaluation loss 0.6771
[690/1246] evaluation loss 0.4471
[720/1246] evaluation loss 0.4623
[750/1246] evaluation loss 0.5030
[780/1246] evaluation loss 0.5530
[810/1246] evaluation loss 0.5836
[840/1246] evaluation loss 0.7648
[870/1246] evaluation loss 0.5131
[900/1246] evaluation loss 0.5356
[930/1246] evaluation loss 0.6297
[960/1246] evaluation loss 0.6337
[990/1246] evaluation loss 0.5258
[1020/1246] evaluation loss 0.4919
[1050/1246] evaluation loss 0.7525
[1080/1246] evaluation loss 0.4753
[1110/1246] evaluation loss 0.5648
[1140/1246] evaluation loss 0.6843
[1170/1246] evaluation loss 0.5309
[1200/1246] evaluation loss 0.5827
[1230/1246] evaluation loss 0.4954
Epoch 6 training loss 0.2998
Epoch 6 evaluation loss 0.5801
Metrics {'Accuracy': tensor(0.7550), 'Precision': tensor(0.5918), 'Recall': tensor(0.4653), 'F1Score': tensor(0.5210), 'MatthewsCorrCoef': tensor(0.3643)}
[30/4984] loss 0.2186
[60/4984] loss 0.2787
[90/4984] loss 0.2974
[120/4984] loss 0.2657
[150/4984] loss 0.2815
[180/4984] loss 0.2205
[210/4984] loss 0.1841
[240/4984] loss 0.3146
[270/4984] loss 0.1930
[300/4984] loss 0.2451
[330/4984] loss 0.2773
[360/4984] loss 0.1673
[390/4984] loss 0.2388
[420/4984] loss 0.2576
[450/4984] loss 0.1935
[480/4984] loss 0.2044
[510/4984] loss 0.2444
[540/4984] loss 0.2897
[570/4984] loss 0.2316
[600/4984] loss 0.2967
[630/4984] loss 0.2737
[660/4984] loss 0.1665
[690/4984] loss 0.2339
[720/4984] loss 0.2520
[750/4984] loss 0.2433
[780/4984] loss 0.2359
[810/4984] loss 0.2682
[840/4984] loss 0.2602
[870/4984] loss 0.2362
[900/4984] loss 0.2490
[930/4984] loss 0.2727
[960/4984] loss 0.2403
[990/4984] loss 0.1811
[1020/4984] loss 0.3014
[1050/4984] loss 0.1856
[1080/4984] loss 0.3025
[1110/4984] loss 0.2615
[1140/4984] loss 0.2863
[1170/4984] loss 0.2645
[1200/4984] loss 0.1859
[1230/4984] loss 0.2523
[1260/4984] loss 0.2972
[1290/4984] loss 0.1993
[1320/4984] loss 0.3302
[1350/4984] loss 0.2708
[1380/4984] loss 0.2240
[1410/4984] loss 0.1976
[1440/4984] loss 0.2302
[1470/4984] loss 0.3072
[1500/4984] loss 0.3503
[1530/4984] loss 0.2375
[1560/4984] loss 0.1797
[1590/4984] loss 0.2310
[1620/4984] loss 0.2316
[1650/4984] loss 0.3008
[1680/4984] loss 0.2417
[1710/4984] loss 0.3196
[1740/4984] loss 0.2447
[1770/4984] loss 0.3115
[1800/4984] loss 0.3814
[1830/4984] loss 0.1927
[1860/4984] loss 0.3008
[1890/4984] loss 0.3317
[1920/4984] loss 0.2712
[1950/4984] loss 0.2115
[1980/4984] loss 0.1862
[2010/4984] loss 0.2693
[2040/4984] loss 0.2377
[2070/4984] loss 0.1757
[2100/4984] loss 0.2545
[2130/4984] loss 0.2603
[2160/4984] loss 0.3940
[2190/4984] loss 0.1929
[2220/4984] loss 0.2194
[2250/4984] loss 0.3047
[2280/4984] loss 0.2162
[2310/4984] loss 0.2460
[2340/4984] loss 0.3137
[2370/4984] loss 0.1962
[2400/4984] loss 0.3156
[2430/4984] loss 0.2879
[2460/4984] loss 0.2065
[2490/4984] loss 0.2543
[2520/4984] loss 0.2627
[2550/4984] loss 0.2541
[2580/4984] loss 0.1976
[2610/4984] loss 0.2475
[2640/4984] loss 0.1693
[2670/4984] loss 0.2617
[2700/4984] loss 0.2467
[2730/4984] loss 0.2463
[2760/4984] loss 0.2478
[2790/4984] loss 0.2228
[2820/4984] loss 0.2762
[2850/4984] loss 0.3298
[2880/4984] loss 0.3269
[2910/4984] loss 0.2044
[2940/4984] loss 0.2681
[2970/4984] loss 0.1784
[3000/4984] loss 0.3089
[3030/4984] loss 0.1851
[3060/4984] loss 0.2858
[3090/4984] loss 0.2376
[3120/4984] loss 0.1905
[3150/4984] loss 0.2724
[3180/4984] loss 0.2358
[3210/4984] loss 0.2438
[3240/4984] loss 0.2397
[3270/4984] loss 0.2900
[3300/4984] loss 0.2809
[3330/4984] loss 0.1624
[3360/4984] loss 0.2897
[3390/4984] loss 0.2429
[3420/4984] loss 0.2041
[3450/4984] loss 0.2123
[3480/4984] loss 0.2803
[3510/4984] loss 0.2045
[3540/4984] loss 0.1845
[3570/4984] loss 0.2663
[3600/4984] loss 0.2635
[3630/4984] loss 0.2471
[3660/4984] loss 0.2742
[3690/4984] loss 0.3079
[3720/4984] loss 0.2646
[3750/4984] loss 0.1779
[3780/4984] loss 0.1594
[3810/4984] loss 0.2018
[3840/4984] loss 0.3401
[3870/4984] loss 0.2827
[3900/4984] loss 0.3991
[3930/4984] loss 0.2068
[3960/4984] loss 0.2288
[3990/4984] loss 0.2470
[4020/4984] loss 0.2172
[4050/4984] loss 0.2801
[4080/4984] loss 0.1767
[4110/4984] loss 0.1776
[4140/4984] loss 0.2429
[4170/4984] loss 0.2574
[4200/4984] loss 0.2009
[4230/4984] loss 0.3038
[4260/4984] loss 0.2890
[4290/4984] loss 0.2785
[4320/4984] loss 0.2275
[4350/4984] loss 0.3080
[4380/4984] loss 0.2181
[4410/4984] loss 0.1752
[4440/4984] loss 0.3353
[4470/4984] loss 0.3034
[4500/4984] loss 0.3341
[4530/4984] loss 0.2563
[4560/4984] loss 0.2509
[4590/4984] loss 0.3269
[4620/4984] loss 0.1807
[4650/4984] loss 0.2914
[4680/4984] loss 0.2601
[4710/4984] loss 0.2722
[4740/4984] loss 0.2187
[4770/4984] loss 0.2816
[4800/4984] loss 0.2174
[4830/4984] loss 0.3193
[4860/4984] loss 0.1926
[4890/4984] loss 0.2973
[4920/4984] loss 0.2855
[4950/4984] loss 0.2157
[4980/4984] loss 0.2277
[30/1246] evaluation loss 0.6033
[60/1246] evaluation loss 0.5473
[90/1246] evaluation loss 0.6706
[120/1246] evaluation loss 0.5587
[150/1246] evaluation loss 0.6529
[180/1246] evaluation loss 0.5105
[210/1246] evaluation loss 0.5725
[240/1246] evaluation loss 0.6310
[270/1246] evaluation loss 0.4959
[300/1246] evaluation loss 0.5540
[330/1246] evaluation loss 0.7957
[360/1246] evaluation loss 0.6216
[390/1246] evaluation loss 0.5079
[420/1246] evaluation loss 0.6870
[450/1246] evaluation loss 0.6895
[480/1246] evaluation loss 0.6306
[510/1246] evaluation loss 0.4642
[540/1246] evaluation loss 0.6503
[570/1246] evaluation loss 0.8179
[600/1246] evaluation loss 0.7856
[630/1246] evaluation loss 0.5880
[660/1246] evaluation loss 0.6359
[690/1246] evaluation loss 0.5832
[720/1246] evaluation loss 0.4293
[750/1246] evaluation loss 0.5128
[780/1246] evaluation loss 0.9008
[810/1246] evaluation loss 0.5503
[840/1246] evaluation loss 0.7616
[870/1246] evaluation loss 0.4754
[900/1246] evaluation loss 0.5211
[930/1246] evaluation loss 0.6294
[960/1246] evaluation loss 0.5916
[990/1246] evaluation loss 0.7152
[1020/1246] evaluation loss 0.6413
[1050/1246] evaluation loss 0.4914
[1080/1246] evaluation loss 0.6436
[1110/1246] evaluation loss 0.6613
[1140/1246] evaluation loss 0.6350
[1170/1246] evaluation loss 0.5376
[1200/1246] evaluation loss 0.7688
[1230/1246] evaluation loss 0.5851
Epoch 7 training loss 0.2517
Epoch 7 evaluation loss 0.6168
Metrics {'Accuracy': tensor(0.7532), 'Precision': tensor(0.5714), 'Recall': tensor(0.5522), 'F1Score': tensor(0.5617), 'MatthewsCorrCoef': tensor(0.3901)}
[30/4984] loss 0.1579
[60/4984] loss 0.2324
[90/4984] loss 0.1430
[120/4984] loss 0.1988
[150/4984] loss 0.1173
[180/4984] loss 0.2559
[210/4984] loss 0.2635
[240/4984] loss 0.2144
[270/4984] loss 0.1716
[300/4984] loss 0.1982
[330/4984] loss 0.1296
[360/4984] loss 0.1949
[390/4984] loss 0.2109
[420/4984] loss 0.2409
[450/4984] loss 0.1433
[480/4984] loss 0.1201
[510/4984] loss 0.1639
[540/4984] loss 0.1335
[570/4984] loss 0.1952
[600/4984] loss 0.1517
[630/4984] loss 0.1834
[660/4984] loss 0.1888
[690/4984] loss 0.1426
[720/4984] loss 0.2455
[750/4984] loss 0.2036
[780/4984] loss 0.1035
[810/4984] loss 0.1611
[840/4984] loss 0.2425
[870/4984] loss 0.1208
[900/4984] loss 0.1575
[930/4984] loss 0.1514
[960/4984] loss 0.1620
[990/4984] loss 0.1668
[1020/4984] loss 0.2068
[1050/4984] loss 0.1675
[1080/4984] loss 0.1278
[1110/4984] loss 0.1823
[1140/4984] loss 0.1696
[1170/4984] loss 0.2384
[1200/4984] loss 0.1657
[1230/4984] loss 0.1801
[1260/4984] loss 0.1572
[1290/4984] loss 0.2204
[1320/4984] loss 0.1501
[1350/4984] loss 0.1648
[1380/4984] loss 0.3068
[1410/4984] loss 0.2177
[1440/4984] loss 0.1406
[1470/4984] loss 0.2089
[1500/4984] loss 0.2026
[1530/4984] loss 0.1578
[1560/4984] loss 0.1314
[1590/4984] loss 0.1471
[1620/4984] loss 0.1465
[1650/4984] loss 0.2008
[1680/4984] loss 0.1942
[1710/4984] loss 0.1870
[1740/4984] loss 0.1974
[1770/4984] loss 0.2056
[1800/4984] loss 0.1638
[1830/4984] loss 0.1826
[1860/4984] loss 0.1781
[1890/4984] loss 0.1787
[1920/4984] loss 0.2170
[1950/4984] loss 0.1624
[1980/4984] loss 0.2013
[2010/4984] loss 0.2374
[2040/4984] loss 0.2082
[2070/4984] loss 0.1702
[2100/4984] loss 0.1298
[2130/4984] loss 0.1065
[2160/4984] loss 0.1056
[2190/4984] loss 0.1798
[2220/4984] loss 0.2049
[2250/4984] loss 0.2448
[2280/4984] loss 0.1190
[2310/4984] loss 0.1657
[2340/4984] loss 0.1409
[2370/4984] loss 0.1420
[2400/4984] loss 0.1658
[2430/4984] loss 0.2021
[2460/4984] loss 0.1740
[2490/4984] loss 0.1562
[2520/4984] loss 0.1075
[2550/4984] loss 0.1412
[2580/4984] loss 0.2694
[2610/4984] loss 0.1566
[2640/4984] loss 0.2340
[2670/4984] loss 0.2773
[2700/4984] loss 0.2912
[2730/4984] loss 0.1212
[2760/4984] loss 0.1810
[2790/4984] loss 0.1641
[2820/4984] loss 0.1446
[2850/4984] loss 0.1768
[2880/4984] loss 0.1987
[2910/4984] loss 0.2418
[2940/4984] loss 0.2024
[2970/4984] loss 0.1798
[3000/4984] loss 0.1056
[3030/4984] loss 0.2046
[3060/4984] loss 0.1193
[3090/4984] loss 0.1873
[3120/4984] loss 0.1493
[3150/4984] loss 0.2149
[3180/4984] loss 0.1821
[3210/4984] loss 0.2079
[3240/4984] loss 0.1766
[3270/4984] loss 0.1172
[3300/4984] loss 0.2398
[3330/4984] loss 0.1266
[3360/4984] loss 0.1456
[3390/4984] loss 0.2132
[3420/4984] loss 0.1645
[3450/4984] loss 0.1683
[3480/4984] loss 0.1499
[3510/4984] loss 0.2074
[3540/4984] loss 0.1960
[3570/4984] loss 0.1336
[3600/4984] loss 0.2485
[3630/4984] loss 0.1528
[3660/4984] loss 0.2798
[3690/4984] loss 0.1172
[3720/4984] loss 0.1928
[3750/4984] loss 0.1895
[3780/4984] loss 0.1257
[3810/4984] loss 0.2021
[3840/4984] loss 0.2521
[3870/4984] loss 0.1594
[3900/4984] loss 0.1648
[3930/4984] loss 0.1844
[3960/4984] loss 0.1846
[3990/4984] loss 0.1288
[4020/4984] loss 0.2577
[4050/4984] loss 0.1662
[4080/4984] loss 0.2488
[4110/4984] loss 0.2147
[4140/4984] loss 0.1422
[4170/4984] loss 0.1185
[4200/4984] loss 0.1690
[4230/4984] loss 0.3009
[4260/4984] loss 0.1748
[4290/4984] loss 0.3666
[4320/4984] loss 0.1704
[4350/4984] loss 0.1450
[4380/4984] loss 0.1827
[4410/4984] loss 0.1482
[4440/4984] loss 0.2081
[4470/4984] loss 0.1854
[4500/4984] loss 0.2516
[4530/4984] loss 0.2773
[4560/4984] loss 0.2580
[4590/4984] loss 0.2434
[4620/4984] loss 0.1415
[4650/4984] loss 0.2202
[4680/4984] loss 0.2342
[4710/4984] loss 0.2376
[4740/4984] loss 0.1759
[4770/4984] loss 0.3492
[4800/4984] loss 0.2455
[4830/4984] loss 0.2347
[4860/4984] loss 0.2345
[4890/4984] loss 0.1987
[4920/4984] loss 0.2265
[4950/4984] loss 0.2583
[4980/4984] loss 0.3064
[30/1246] evaluation loss 0.5021
[60/1246] evaluation loss 0.6504
[90/1246] evaluation loss 0.6420
[120/1246] evaluation loss 0.5968
[150/1246] evaluation loss 0.9349
[180/1246] evaluation loss 0.5270
[210/1246] evaluation loss 0.7370
[240/1246] evaluation loss 0.6268
[270/1246] evaluation loss 0.6879
[300/1246] evaluation loss 0.7066
[330/1246] evaluation loss 0.7683
[360/1246] evaluation loss 0.6265
[390/1246] evaluation loss 0.5613
[420/1246] evaluation loss 0.6443
[450/1246] evaluation loss 0.6003
[480/1246] evaluation loss 0.6329
[510/1246] evaluation loss 0.6896
[540/1246] evaluation loss 0.5788
[570/1246] evaluation loss 0.8017
[600/1246] evaluation loss 0.7475
[630/1246] evaluation loss 0.5671
[660/1246] evaluation loss 0.7662
[690/1246] evaluation loss 0.7171
[720/1246] evaluation loss 0.6813
[750/1246] evaluation loss 0.7247
[780/1246] evaluation loss 0.6379
[810/1246] evaluation loss 0.7130
[840/1246] evaluation loss 0.5287
[870/1246] evaluation loss 0.6755
[900/1246] evaluation loss 0.7296
[930/1246] evaluation loss 0.6031
[960/1246] evaluation loss 0.5588
[990/1246] evaluation loss 0.4650
[1020/1246] evaluation loss 0.6360
[1050/1246] evaluation loss 0.5678
[1080/1246] evaluation loss 0.5262
[1110/1246] evaluation loss 0.6924
[1140/1246] evaluation loss 0.6483
[1170/1246] evaluation loss 0.6701
[1200/1246] evaluation loss 0.7543
[1230/1246] evaluation loss 0.6826
Epoch 8 training loss 0.1878
Epoch 8 evaluation loss 0.6569
Metrics {'Accuracy': tensor(0.7275), 'Precision': tensor(0.5294), 'Recall': tensor(0.4359), 'F1Score': tensor(0.4781), 'MatthewsCorrCoef': tensor(0.2986)}
[30/4984] loss 0.1837
[60/4984] loss 0.1598
[90/4984] loss 0.0895
[120/4984] loss 0.1251
[150/4984] loss 0.1421
[180/4984] loss 0.1184
[210/4984] loss 0.1094
[240/4984] loss 0.1493
[270/4984] loss 0.1591
[300/4984] loss 0.1189
[330/4984] loss 0.1447
[360/4984] loss 0.1177
[390/4984] loss 0.1298
[420/4984] loss 0.1430
[450/4984] loss 0.1883
[480/4984] loss 0.1709
[510/4984] loss 0.1845
[540/4984] loss 0.1619
[570/4984] loss 0.1394
[600/4984] loss 0.1213
[630/4984] loss 0.1016
[660/4984] loss 0.1379
[690/4984] loss 0.1272
[720/4984] loss 0.1359
[750/4984] loss 0.1062
[780/4984] loss 0.1738
[810/4984] loss 0.1348
[840/4984] loss 0.1105
[870/4984] loss 0.0786
[900/4984] loss 0.1370
[930/4984] loss 0.1215
[960/4984] loss 0.0924
[990/4984] loss 0.1389
[1020/4984] loss 0.0933
[1050/4984] loss 0.1223
[1080/4984] loss 0.0793
[1110/4984] loss 0.1299
[1140/4984] loss 0.0832
[1170/4984] loss 0.1237
[1200/4984] loss 0.1348
[1230/4984] loss 0.0928
[1260/4984] loss 0.0924
[1290/4984] loss 0.1651
[1320/4984] loss 0.1025
[1350/4984] loss 0.1974
[1380/4984] loss 0.1629
[1410/4984] loss 0.1336
[1440/4984] loss 0.0597
[1470/4984] loss 0.0956
[1500/4984] loss 0.1028
[1530/4984] loss 0.1507
[1560/4984] loss 0.1643
[1590/4984] loss 0.1930
[1620/4984] loss 0.1199
[1650/4984] loss 0.1471
[1680/4984] loss 0.1365
[1710/4984] loss 0.1690
[1740/4984] loss 0.0907
[1770/4984] loss 0.1453
[1800/4984] loss 0.1036
[1830/4984] loss 0.1282
[1860/4984] loss 0.1305
[1890/4984] loss 0.1273
[1920/4984] loss 0.0934
[1950/4984] loss 0.1129
[1980/4984] loss 0.1067
[2010/4984] loss 0.0962
[2040/4984] loss 0.0934
[2070/4984] loss 0.0640
[2100/4984] loss 0.1796
[2130/4984] loss 0.1866
[2160/4984] loss 0.1894
[2190/4984] loss 0.1080
[2220/4984] loss 0.1682
[2250/4984] loss 0.1394
[2280/4984] loss 0.0727
[2310/4984] loss 0.0918
[2340/4984] loss 0.1364
[2370/4984] loss 0.1445
[2400/4984] loss 0.1094
[2430/4984] loss 0.1273
[2460/4984] loss 0.1175
[2490/4984] loss 0.0916
[2520/4984] loss 0.1321
[2550/4984] loss 0.1003
[2580/4984] loss 0.1395
[2610/4984] loss 0.1422
[2640/4984] loss 0.0995
[2670/4984] loss 0.1480
[2700/4984] loss 0.1036
[2730/4984] loss 0.1483
[2760/4984] loss 0.1046
[2790/4984] loss 0.0925
[2820/4984] loss 0.1097
[2850/4984] loss 0.1825
[2880/4984] loss 0.1431
[2910/4984] loss 0.1848
[2940/4984] loss 0.2061
[2970/4984] loss 0.1667
[3000/4984] loss 0.2146
[3030/4984] loss 0.1267
[3060/4984] loss 0.1246
[3090/4984] loss 0.0828
[3120/4984] loss 0.1436
[3150/4984] loss 0.0840
[3180/4984] loss 0.1245
[3210/4984] loss 0.0893
[3240/4984] loss 0.1754
[3270/4984] loss 0.1325
[3300/4984] loss 0.0949
[3330/4984] loss 0.1325
[3360/4984] loss 0.1868
[3390/4984] loss 0.0861
[3420/4984] loss 0.1232
[3450/4984] loss 0.1637
[3480/4984] loss 0.1404
[3510/4984] loss 0.1161
[3540/4984] loss 0.1376
[3570/4984] loss 0.1650
[3600/4984] loss 0.1391
[3630/4984] loss 0.1075
[3660/4984] loss 0.0977
[3690/4984] loss 0.1043
[3720/4984] loss 0.0828
[3750/4984] loss 0.1038
[3780/4984] loss 0.0917
[3810/4984] loss 0.1116
[3840/4984] loss 0.0952
[3870/4984] loss 0.0694
[3900/4984] loss 0.0860
[3930/4984] loss 0.1402
[3960/4984] loss 0.2077
[3990/4984] loss 0.1561
[4020/4984] loss 0.0907
[4050/4984] loss 0.1241
[4080/4984] loss 0.2016
[4110/4984] loss 0.1953
[4140/4984] loss 0.1610
[4170/4984] loss 0.2045
[4200/4984] loss 0.1039
[4230/4984] loss 0.1817
[4260/4984] loss 0.1892
[4290/4984] loss 0.1476
[4320/4984] loss 0.1076
[4350/4984] loss 0.0716
[4380/4984] loss 0.1196
[4410/4984] loss 0.1729
[4440/4984] loss 0.1295
[4470/4984] loss 0.1126
[4500/4984] loss 0.1035
[4530/4984] loss 0.1297
[4560/4984] loss 0.1455
[4590/4984] loss 0.1913
[4620/4984] loss 0.1489
[4650/4984] loss 0.1001
[4680/4984] loss 0.1190
[4710/4984] loss 0.2350
[4740/4984] loss 0.1697
[4770/4984] loss 0.1409
[4800/4984] loss 0.1257
[4830/4984] loss 0.1281
[4860/4984] loss 0.1752
[4890/4984] loss 0.0963
[4920/4984] loss 0.1430
[4950/4984] loss 0.2431
[4980/4984] loss 0.0975
[30/1246] evaluation loss 0.5182
[60/1246] evaluation loss 0.7756
[90/1246] evaluation loss 0.9255
[120/1246] evaluation loss 0.6375
[150/1246] evaluation loss 0.6717
[180/1246] evaluation loss 1.0165
[210/1246] evaluation loss 0.7321
[240/1246] evaluation loss 0.7564
[270/1246] evaluation loss 0.9334
[300/1246] evaluation loss 0.6353
[330/1246] evaluation loss 0.9033
[360/1246] evaluation loss 0.7748
[390/1246] evaluation loss 0.5958
[420/1246] evaluation loss 0.8585
[450/1246] evaluation loss 0.9876
[480/1246] evaluation loss 0.7012
[510/1246] evaluation loss 0.9676
[540/1246] evaluation loss 0.8133
[570/1246] evaluation loss 0.6786
[600/1246] evaluation loss 0.6387
[630/1246] evaluation loss 0.7854
[660/1246] evaluation loss 0.7468
[690/1246] evaluation loss 0.7367
[720/1246] evaluation loss 0.5984
[750/1246] evaluation loss 0.6259
[780/1246] evaluation loss 0.6430
[810/1246] evaluation loss 0.9050
[840/1246] evaluation loss 1.1316
[870/1246] evaluation loss 0.7607
[900/1246] evaluation loss 0.7383
[930/1246] evaluation loss 0.5197
[960/1246] evaluation loss 0.8959
[990/1246] evaluation loss 0.8673
[1020/1246] evaluation loss 0.6476
[1050/1246] evaluation loss 0.6487
[1080/1246] evaluation loss 0.6982
[1110/1246] evaluation loss 1.3051
[1140/1246] evaluation loss 0.9706
[1170/1246] evaluation loss 0.9709
[1200/1246] evaluation loss 0.8478
[1230/1246] evaluation loss 0.7993
Epoch 9 training loss 0.1321
Epoch 9 evaluation loss 0.7883
Metrics {'Accuracy': tensor(0.7590), 'Precision': tensor(0.6151), 'Recall': tensor(0.4233), 'F1Score': tensor(0.5015), 'MatthewsCorrCoef': tensor(0.3603)}
[30/4984] loss 0.0919
[60/4984] loss 0.0499
[90/4984] loss 0.0694
[120/4984] loss 0.0480
[150/4984] loss 0.1379
[180/4984] loss 0.0665
[210/4984] loss 0.0534
[240/4984] loss 0.0470
[270/4984] loss 0.0697
[300/4984] loss 0.0800
[330/4984] loss 0.0466
[360/4984] loss 0.0951
[390/4984] loss 0.0592
[420/4984] loss 0.1162
[450/4984] loss 0.0516
[480/4984] loss 0.0757
[510/4984] loss 0.0681
[540/4984] loss 0.0754
[570/4984] loss 0.0658
[600/4984] loss 0.0649
[630/4984] loss 0.1347
[660/4984] loss 0.0548
[690/4984] loss 0.1507
[720/4984] loss 0.0747
[750/4984] loss 0.0963
[780/4984] loss 0.0865
[810/4984] loss 0.1054
[840/4984] loss 0.0875
[870/4984] loss 0.1010
[900/4984] loss 0.1021
[930/4984] loss 0.0528
[960/4984] loss 0.1274
[990/4984] loss 0.0539
[1020/4984] loss 0.1001
[1050/4984] loss 0.1205
[1080/4984] loss 0.0661
[1110/4984] loss 0.0320
[1140/4984] loss 0.0690
[1170/4984] loss 0.1259
[1200/4984] loss 0.0741
[1230/4984] loss 0.1048
[1260/4984] loss 0.1341
[1290/4984] loss 0.0437
[1320/4984] loss 0.1055
[1350/4984] loss 0.0901
[1380/4984] loss 0.0497
[1410/4984] loss 0.0704
[1440/4984] loss 0.0549
[1470/4984] loss 0.1130
[1500/4984] loss 0.0848
[1530/4984] loss 0.0863
[1560/4984] loss 0.0788
[1590/4984] loss 0.0680
[1620/4984] loss 0.0758
[1650/4984] loss 0.0925
[1680/4984] loss 0.0752
[1710/4984] loss 0.0899
[1740/4984] loss 0.1307
[1770/4984] loss 0.0870
[1800/4984] loss 0.0993
[1830/4984] loss 0.0979
[1860/4984] loss 0.0733
[1890/4984] loss 0.0539
[1920/4984] loss 0.0932
[1950/4984] loss 0.0827
[1980/4984] loss 0.0690
[2010/4984] loss 0.0657
[2040/4984] loss 0.0534
[2070/4984] loss 0.0637
[2100/4984] loss 0.0490
[2130/4984] loss 0.1414
[2160/4984] loss 0.0853
[2190/4984] loss 0.1122
[2220/4984] loss 0.0877
[2250/4984] loss 0.0751
[2280/4984] loss 0.0429
[2310/4984] loss 0.0309
[2340/4984] loss 0.0226
[2370/4984] loss 0.0632
[2400/4984] loss 0.0392
[2430/4984] loss 0.1625
[2460/4984] loss 0.0670
[2490/4984] loss 0.0609
[2520/4984] loss 0.1185
[2550/4984] loss 0.0990
[2580/4984] loss 0.1045
[2610/4984] loss 0.0763
[2640/4984] loss 0.0710
[2670/4984] loss 0.1276
[2700/4984] loss 0.1497
[2730/4984] loss 0.0706
[2760/4984] loss 0.0780
[2790/4984] loss 0.2476
[2820/4984] loss 0.1197
[2850/4984] loss 0.1290
[2880/4984] loss 0.0700
[2910/4984] loss 0.0531
[2940/4984] loss 0.1097
[2970/4984] loss 0.1577
[3000/4984] loss 0.0985
[3030/4984] loss 0.1327
[3060/4984] loss 0.0867
[3090/4984] loss 0.0717
[3120/4984] loss 0.1357
[3150/4984] loss 0.0398
[3180/4984] loss 0.0700
[3210/4984] loss 0.0849
[3240/4984] loss 0.0990
[3270/4984] loss 0.1098
[3300/4984] loss 0.0927
[3330/4984] loss 0.0798
[3360/4984] loss 0.0615
[3390/4984] loss 0.1088
[3420/4984] loss 0.1036
[3450/4984] loss 0.1018
[3480/4984] loss 0.0982
[3510/4984] loss 0.0636
[3540/4984] loss 0.0415
[3570/4984] loss 0.1654
[3600/4984] loss 0.1236
[3630/4984] loss 0.0541
[3660/4984] loss 0.0610
[3690/4984] loss 0.0578
[3720/4984] loss 0.1860
[3750/4984] loss 0.0757
[3780/4984] loss 0.0651
[3810/4984] loss 0.0995
[3840/4984] loss 0.0706
[3870/4984] loss 0.0605
[3900/4984] loss 0.1737
[3930/4984] loss 0.0844
[3960/4984] loss 0.0904
[3990/4984] loss 0.0849
[4020/4984] loss 0.0586
[4050/4984] loss 0.1000
[4080/4984] loss 0.1127
[4110/4984] loss 0.0883
[4140/4984] loss 0.0999
[4170/4984] loss 0.0529
[4200/4984] loss 0.0815
[4230/4984] loss 0.0534
[4260/4984] loss 0.1582
[4290/4984] loss 0.8863
[4320/4984] loss 0.2747
[4350/4984] loss 0.4039
[4380/4984] loss 0.2879
[4410/4984] loss 0.1811
[4440/4984] loss 0.2088
[4470/4984] loss 0.2660
[4500/4984] loss 0.2177
[4530/4984] loss 0.2312
[4560/4984] loss 0.2157
[4590/4984] loss 0.2097
[4620/4984] loss 0.2567
[4650/4984] loss 0.1387
[4680/4984] loss 0.1364
[4710/4984] loss 0.1541
[4740/4984] loss 0.2320
[4770/4984] loss 0.2693
[4800/4984] loss 0.1438
[4830/4984] loss 0.1631
[4860/4984] loss 0.1106
[4890/4984] loss 0.1682
[4920/4984] loss 0.1701
[4950/4984] loss 0.1195
[4980/4984] loss 0.1841
[30/1246] evaluation loss 1.0000
[60/1246] evaluation loss 0.9213
[90/1246] evaluation loss 0.8303
[120/1246] evaluation loss 0.8822
[150/1246] evaluation loss 0.9773
[180/1246] evaluation loss 0.7168
[210/1246] evaluation loss 0.6665
[240/1246] evaluation loss 0.9770
[270/1246] evaluation loss 0.6418
[300/1246] evaluation loss 0.9903
[330/1246] evaluation loss 0.4273
[360/1246] evaluation loss 0.8361
[390/1246] evaluation loss 0.8295
[420/1246] evaluation loss 0.7825
[450/1246] evaluation loss 0.8592
[480/1246] evaluation loss 1.0476
[510/1246] evaluation loss 0.8799
[540/1246] evaluation loss 0.6419
[570/1246] evaluation loss 0.5893
[600/1246] evaluation loss 0.9674
[630/1246] evaluation loss 0.7467
[660/1246] evaluation loss 0.9423
[690/1246] evaluation loss 0.6028
[720/1246] evaluation loss 0.7003
[750/1246] evaluation loss 0.8203
[780/1246] evaluation loss 0.7885
[810/1246] evaluation loss 0.5932
[840/1246] evaluation loss 0.8302
[870/1246] evaluation loss 0.9737
[900/1246] evaluation loss 0.9633
[930/1246] evaluation loss 0.7782
[960/1246] evaluation loss 0.8431
[990/1246] evaluation loss 0.7700
[1020/1246] evaluation loss 0.8001
[1050/1246] evaluation loss 0.7225
[1080/1246] evaluation loss 0.8425
[1110/1246] evaluation loss 0.7657
[1140/1246] evaluation loss 0.6714
[1170/1246] evaluation loss 0.8617
[1200/1246] evaluation loss 0.9760
[1230/1246] evaluation loss 0.8794
Epoch 10 training loss 0.1086
Epoch 10 evaluation loss 0.8118
Metrics {'Accuracy': tensor(0.7368), 'Precision': tensor(0.5451), 'Recall': tensor(0.4870), 'F1Score': tensor(0.5144), 'MatthewsCorrCoef': tensor(0.3356)}
